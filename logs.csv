,fname,text
0,spark_logs_18410,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@6d01dd03, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175bc40@2b04cf3d\n\n"""
1,spark_logs_18500,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@656b7e51,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
2,spark_logs_18401,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@700753c1, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2853/0x0000000841743840@20d9d5f4\n\n"""
3,spark_logs_18454,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@52a81fed, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x0000000841753c40@6a41607a\n\n"""
4,spark_logs_18490,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@54cc28a0, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2873/0x000000084175bc40@318d0cb0\n\n"""
5,spark_logs_18472,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@225d8333, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2880/0x000000084175e840@70cb56d2\n\n"""
6,spark_logs_18436,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@2f2faef1,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
7,spark_logs_18517,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@168de89e, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2853/0x0000000841743440@353a85e\n\n"""
8,spark_logs_18463,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@ea008df, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2888/0x0000000841762040@6ff505d9\n\n"""
9,spark_logs_18427,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@658b2c5d,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
10,spark_logs_18508,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@553485a7, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175bc40@7cfa7915\n\n"""
11,spark_logs_18481,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@29bf7b5f, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2852/0x000000084173ac40@6a498c5d\n\n"""
12,spark_logs_18445,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@3a9a18d6, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175c840@249717f0\n\n"""
13,spark_logs_18414,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@44ce5b34,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
14,spark_logs_18432,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@342513f8, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175c840@74344275\n\n"""
15,spark_logs_18423,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@225d8333, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2853/0x0000000841743440@70cb56d2\n\n"""
16,spark_logs_18405,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@fb361ec,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
17,spark_logs_18441,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@66954c22, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2853/0x000000084173b840@4c7e7f06\n\n"""
18,spark_logs_18458,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@65f93777,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
19,spark_logs_18494,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@9135dbd,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
20,spark_logs_18476,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@6e6348b2,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
21,spark_logs_18467,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@25fc9af,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
22,spark_logs_18485,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@5e570e98,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
23,spark_logs_18449,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@5f22b318,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
24,spark_logs_18511,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@56fc0c1e, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175c840@503d63cb\n\n"""
25,spark_logs_18430,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@76d73e8b,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
26,spark_logs_18502,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@682ac41f, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2853/0x000000084173b840@44a21034\n\n"""
27,spark_logs_18421,"""== Physical Plan ==\n* Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [2]: [person_name#4, person_age#5]\nArguments: [person_name#4, person_age#5], MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n"""
28,spark_logs_18438,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@693645c0, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2880/0x000000084175e840@503fe010\n\n"""
29,spark_logs_18429,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@36f498c, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2881/0x000000084175e840@73ba8dbb\n\n"""
30,spark_logs_18452,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@21844c56,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
31,spark_logs_18416,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@28756ee2, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2853/0x0000000841743440@384bfcb6\n\n"""
32,spark_logs_18470,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@24f105f1,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
33,spark_logs_18515,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@292c9b95,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
34,spark_logs_18461,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@2ed09de2,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
35,spark_logs_18506,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@5d78dffd,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
36,spark_logs_18407,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@653de52a, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175bc40@76e4eba6\n\n"""
37,spark_logs_18443,"""== Physical Plan ==\n* Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [2]: [person_name#4, person_age#5]\nArguments: [person_name#4, person_age#5], MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n"""
38,spark_logs_18496,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@4db99594, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175bc40@2222e01f\n\n"""
39,spark_logs_18478,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@4c99ab7d, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2876/0x0000000841756c40@5db56f55\n\n"""
40,spark_logs_18469,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@28756ee2, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2878/0x000000084175c440@384bfcb6\n\n"""
41,spark_logs_18487,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@3b2e3d8d, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x0000000841756c40@1a3b7ed3\n\n"""
42,spark_logs_18411,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@163e08e7,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
43,spark_logs_18420,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@29ad7892,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
44,spark_logs_18499,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@75321c2d, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2880/0x000000084175e840@5fa6d8a8\n\n"""
45,spark_logs_18402,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@47656706,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
46,spark_logs_18419,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@41a9ed5a, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x0000000841755840@5bed3747\n\n"""
47,spark_logs_18491,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@23a3950c,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
48,spark_logs_18455,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@5ffcdae8,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
49,spark_logs_18518,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@2a15bf4e,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
50,spark_logs_18473,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@678616c4,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
51,spark_logs_18509,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@30eadb9d,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
52,spark_logs_18464,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@1fd3ac59,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
53,spark_logs_18446,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@3da419d5,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
54,spark_logs_18482,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@e6b7015,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
55,spark_logs_18451,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@25dbff4, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175c840@5dcc4a33\n\n"""
56,spark_logs_18433,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@48206253,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
57,spark_logs_18514,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@3ba8f228, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2852/0x000000084173ac40@4c72bff8\n\n"""
58,spark_logs_18424,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@7aab54c1,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
59,spark_logs_18505,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@47bf2962, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2878/0x0000000841756c40@6d5c06ed\n\n"""
60,spark_logs_18460,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@4d358ded, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2853/0x000000084173b440@20a642bc\n\n"""
61,spark_logs_18442,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@4d242043,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
62,spark_logs_18413,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@6191fca5, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175bc40@41293f70\n\n"""
63,spark_logs_18512,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@7ed2efd2,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
64,spark_logs_18503,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@2bfc790e,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
65,spark_logs_18404,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@5e45da5d, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175bc40@7115c6f\n\n"""
66,spark_logs_18493,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@7c8d8df, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2880/0x000000084175e840@339d7133\n\n"""
67,spark_logs_18457,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@28c93576, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175c840@a1b1e78\n\n"""
68,spark_logs_18439,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@58c7cd52,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
69,spark_logs_18475,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@2d855765, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175c840@63c18b9f\n\n"""
70,spark_logs_18466,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@25dbff4, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2853/0x000000084173b440@5dcc4a33\n\n"""
71,spark_logs_18448,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@6feff8fa, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2877/0x000000084175c840@551b77f3\n\n"""
72,spark_logs_18484,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@29bf7b5f, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2878/0x0000000841756c40@6a498c5d\n\n"""
73,spark_logs_18417,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@4df39cbd,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
74,spark_logs_18435,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@1e9b78a9, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2853/0x0000000841743840@3d690fde\n\n"""
75,spark_logs_18426,"""== Physical Plan ==\nAtomicReplaceTableAsSelect (4)\n+- * Project (3)\n   +- ArrowEvalPython (2)\n      +- * Range (1)\n\n\n(1) Range [codegen id : 1]\nOutput [1]: [id#11L]\nArguments: Range (0, 10000, step=1, splits=Some(8))\n\n(2) ArrowEvalPython\nInput [1]: [id#11L]\nArguments: [pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L), pandasGenerateText(id#11L)], [pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97], 200\n\n(3) Project [codegen id : 2]\nOutput [16]: [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38]\nInput [11]: [id#11L, pythonUDF0#88, pythonUDF1#89, pythonUDF2#90, pythonUDF3#91, pythonUDF4#92, pythonUDF5#93, pythonUDF6#94, pythonUDF7#95, pythonUDF8#96, pythonUDF9#97]\n\n(4) AtomicReplaceTableAsSelect\nInput [16]: [name#14, address#16, email#18, aba_routing#20, bank_country#22, account_no#24, int_account_no#26, swift11#28, credit_card_number#30, credit_card_provider#32, event_type#33, event_ts#34, longitude#35, latitude#36, transaction_currency#37, transaction_amount#38]\nArguments: org.apache.iceberg.spark.SparkSessionCatalog@5fa4c523, CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco, Project [CASE WHEN (rand(-515339985) > 0.1) THEN pythonUDF0#88 END AS name#14, pythonUDF1#89 AS address#16, pythonUDF2#90 AS email#18, pythonUDF3#91 AS aba_routing#20, pythonUDF4#92 AS bank_country#22, pythonUDF5#93 AS account_no#24, pythonUDF6#94 AS int_account_no#26, pythonUDF7#95 AS swift11#28, pythonUDF8#96 AS credit_card_number#30, pythonUDF9#97 AS credit_card_provider#32, [purchase,cash_advance][cast(((round((rand(765824677) * 1.0), 0) * 1.0) + 0.0) as int)] AS event_type#33, cast(((round((rand(-1253845667) * 526979.0), 0) * 60.0) + 1.5778404E9) as timestamp) AS event_ts#34, cast(((round((rand(-1284103195) * 360.0), 0) * 1.0) + -180.0) as float) AS longitude#35, cast(((round((rand(1171160475) * 180.0), 0) * 1.0) + -90.0) as float) AS latitude#36, [USD,EUR,KWD,BHD,GBP,CHF,MEX][cast((((((id#11L % 7) + 7) % 7) * 1) + 0) as int)] AS transaction_currency#37, cast(((round((rand(130620005) * 29999.0), 0) * 1.0) + 0.01) as decimal(10,0)) AS transaction_amount#38], [write.format.default=parquet, provider=iceberg, owner=pauldefusco], [], true, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2880/0x000000084175e840@3a1f7ab9\n\n"""
76,spark_logs_18408,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@55c6e164,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
77,spark_logs_18497,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@73ce5973,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
78,spark_logs_18479,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@cdb9423,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
79,spark_logs_18488,"""== Physical Plan ==\nAdaptiveSparkPlan (13)\n+- == Final Plan ==\n   * Sort (8)\n   +- * HashAggregate (7)\n      +- * HashAggregate (6)\n         +- * Filter (5)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n+- == Initial Plan ==\n   Sort (12)\n   +- HashAggregate (11)\n      +- HashAggregate (10)\n         +- Filter (9)\n            +- InMemoryTableScan (1)\n                  +- InMemoryRelation (2)\n                        +- * ColumnarToRow (4)\n                           +- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco (3)\n\n\n(1) InMemoryTableScan\nOutput [1]: [transaction_currency#14]\nArguments: [transaction_currency#14], [isnotnull(transaction_currency#14)]\n\n(2) InMemoryRelation\nArguments: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@7df2511,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) ColumnarToRow\n+- BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco[name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15] spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=] RuntimeFilters: []\n,None)\n\n(3) BatchScan Iceberg spark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco\nOutput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\nspark_catalog.CDE_DEMO_pdefusco_BNK.BANKING_TRANSACTIONS_pdefusco [filters=]\n\n(4) ColumnarToRow [codegen id : 1]\nInput [16]: [name#0, address#1, email#2, aba_routing#3, bank_country#4, account_no#5, int_account_no#6, swift11#7, credit_card_number#8, credit_card_provider#9, event_type#10, event_ts#11, longitude#12, latitude#13, transaction_currency#14, transaction_amount#15]\n\n(5) Filter [codegen id : 1]\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(6) HashAggregate [codegen id : 1]\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(7) HashAggregate [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(8) Sort [codegen id : 1]\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(9) Filter\nInput [1]: [transaction_currency#14]\nCondition : isnotnull(transaction_currency#14)\n\n(10) HashAggregate\nInput [1]: [transaction_currency#14]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [partial_count(1)]\nAggregate Attributes [1]: [count#11645L]\nResults [2]: [transaction_currency#14, count#11646L]\n\n(11) HashAggregate\nInput [2]: [transaction_currency#14, count#11646L]\nKeys [1]: [transaction_currency#14]\nFunctions [1]: [count(1)]\nAggregate Attributes [1]: [count(1)#11401L]\nResults [2]: [transaction_currency#14, count(1)#11401L AS count#11402L]\n\n(12) Sort\nInput [2]: [transaction_currency#14, count#11402L]\nArguments: [transaction_currency#14 ASC NULLS FIRST], true, 0\n\n(13) AdaptiveSparkPlan\nOutput [2]: [transaction_currency#14, count#11402L]\nArguments: isFinalPlan=true\n\n"""
